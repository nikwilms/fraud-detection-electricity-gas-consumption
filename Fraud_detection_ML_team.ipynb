{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fraud Detection in Electricity and Gas Consumption Challenge\n",
    "\n",
    "This is a simple starter notebook based on the tutorial prepared by Joy Wawira. Check out the article [here](https://zindi.africa/learn/fraud-detection-in-electricity-and-gas-consumption-challenge-tutorial) for a more detailed description of the steps taken.\n",
    "\n",
    "This notebook covers:\n",
    "- Downloading the data straight from Zindi and onto colab\n",
    "- Loading the data and carrying out simple EDA to understand the data and prepare for modelling \n",
    "- Preprocessing the data and feature engineering \n",
    "- Creating a simple LGBM model and predicting on the test set\n",
    "- Prepare submission file and save as csv\n",
    "- Some tips on how to improve model performance and your score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Columns explanation**\n",
    "\n",
    "\n",
    "About\n",
    "The data provided by STEG is composed of two files. The first one is comprised of client data and the second one contains billing history from 2005 to 2019.\n",
    "\n",
    "There are 2 .zip files for download, train.zip, and test.zip and a SampleSubmission.csv. In each .zip file you will find a client and invoice file.\n",
    "\n",
    "Variable definitions\n",
    "\n",
    "Client:\n",
    "\n",
    "* Client_id: Unique id for client\n",
    "* District: District where the client is\n",
    "* Client_catg: Category client belongs to\n",
    "* Region: Area where the client is\n",
    "* Creation_date: Date client joined\n",
    "* Target: fraud:1 , not fraud: 0\n",
    "\n",
    "Invoice data\n",
    "\n",
    "* Client_id: Unique id for the client\n",
    "* Invoice_date: Date of the invoice\n",
    "* Tarif_type: Type of tax\n",
    "* Counter_number:\n",
    "* Counter_statue: takes up to 5 values such as working fine, not working, on hold statue, ect\n",
    "* Counter_code:\n",
    "* Reading_remarque: notes that the STEG agent takes during his visit to the client (e.g: If the counter shows something wrong, the agent gives a bad score)\n",
    "* Counter_coefficient: An additional coefficient to be added when standard consumption is exceeded\n",
    "* Consommation_level_1: Consumption_level_1\n",
    "* Consommation_level_2: Consumption_level_2\n",
    "* Consommation_level_3: Consumption_level_3\n",
    "* Consommation_level_4: Consumption_level_4\n",
    "* Old_index: Old index\n",
    "* New_index: New index\n",
    "* Months_number: Month number\n",
    "* Counter_type: Type of counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'convert_dtype_cat_date' from 'src.preprocessing.cleaning' (/Users/neuefische/repos/ml_project_mariusbosch/gas-fraud-team-crime/src/preprocessing/cleaning.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m \u001b[39mimport\u001b[39;00m MinMaxScaler, StandardScaler, RobustScaler, OneHotEncoder, OrdinalEncoder\n\u001b[1;32m     15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39magg_invoice\u001b[39;00m \u001b[39mimport\u001b[39;00m agg_invoice_num_mode_no_monthly_weighting\n\u001b[0;32m---> 16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcleaning\u001b[39;00m \u001b[39mimport\u001b[39;00m convert_dtype_cat_date\n\u001b[1;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msvm\u001b[39;00m \u001b[39mimport\u001b[39;00m SVC\n\u001b[1;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m fbeta_score, make_scorer\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'convert_dtype_cat_date' from 'src.preprocessing.cleaning' (/Users/neuefische/repos/ml_project_mariusbosch/gas-fraud-team-crime/src/preprocessing/cleaning.py)"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler, OneHotEncoder, OrdinalEncoder\n",
    "from src.preprocessing.agg_invoice import agg_invoice_num_mode_no_monthly_weighting\n",
    "from src.preprocessing.cleaning import convert_dtype_cat_date\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score, roc_curve, confusion_matrix, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import warnings\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "plt.rcParams.update({ \"figure.figsize\" : (8, 5),\"axes.facecolor\" : \"white\", \"axes.edgecolor\":  \"black\"})\n",
    "plt.rcParams[\"figure.facecolor\"]= \"w\"\n",
    "pd.plotting.register_matplotlib_converters()\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "\n",
    "\n",
    "# Define a plotting style to be used for all plots in this notebook\n",
    "plt.style.use('tableau-colorblind10')\n",
    "\n",
    "#from sqalchemy import create_engine\n",
    "#from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_client_train = pd.read_csv('data/train/client_train.csv')\n",
    "df_invoice_train = pd.read_csv('data/train/invoice_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date time format\n",
    "\n",
    "df_invoice_train['invoice_date'] = pd.to_datetime(df_invoice_train['invoice_date'])\n",
    "df_client_train['creation_date'] = pd.to_datetime(df_client_train['creation_date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering (aggregate)\n",
    "\n",
    "df_invoice= agg_invoice_num_mode_no_monthly_weighting(df_invoice_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge dataframes\n",
    "\n",
    "df_combined = pd.merge(df_client_train, df_invoice, on='client_id', how='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call cleaning function (convert categories, rename columns, etc.)\n",
    "\n",
    "df_combined = convert_dtype_cat_date(df_combined) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 135493 entries, 0 to 135492\n",
      "Data columns (total 18 columns):\n",
      " #   Column                Non-Null Count   Dtype         \n",
      "---  ------                --------------   -----         \n",
      " 0   district              135493 non-null  category      \n",
      " 1   client_id             135493 non-null  object        \n",
      " 2   client_catg           135493 non-null  category      \n",
      " 3   region                135493 non-null  category      \n",
      " 4   creation_date         135493 non-null  datetime64[ns]\n",
      " 5   target                135493 non-null  float64       \n",
      " 6   consommation_level_1  135493 non-null  float64       \n",
      " 7   consommation_level_2  135493 non-null  float64       \n",
      " 8   consommation_level_3  135493 non-null  float64       \n",
      " 9   consommation_level_4  135493 non-null  float64       \n",
      " 10  counter_coefficient   135493 non-null  float64       \n",
      " 11  months_number         135493 non-null  float64       \n",
      " 12  invoice_date          135493 non-null  datetime64[ns]\n",
      " 13  tarif_type            135493 non-null  category      \n",
      " 14  counter_statue        135493 non-null  category      \n",
      " 15  counter_code          135493 non-null  category      \n",
      " 16  reading_remarque      135493 non-null  category      \n",
      " 17  counter_type          135493 non-null  category      \n",
      "dtypes: category(8), datetime64[ns](2), float64(7), object(1)\n",
      "memory usage: 11.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df_combined.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 135493 entries, 0 to 135492\n",
      "Columns: 108 entries, client_id to counter_type_GAZ\n",
      "dtypes: bool(98), datetime64[ns](2), float64(7), object(1)\n",
      "memory usage: 23.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# Feature engineering (one hot encode all categorical variables)\n",
    "\n",
    "categorical_variables = ['district','client_catg','region', 'tarif_type','counter_statue','counter_code','reading_remarque','counter_type'] # all categorical variables\n",
    "df_combined_encoded = [[]]\n",
    "df_combined_encoded = pd.get_dummies(df_combined, columns=categorical_variables, drop_first=True) # one hot encode all categorical variables\n",
    "\n",
    "#df_combined_encoded.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 135493 entries, 0 to 135492\n",
      "Columns: 108 entries, client_id to counter_type_GAZ\n",
      "dtypes: bool(98), float64(7), int64(2), object(1)\n",
      "memory usage: 23.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# reconvert datetime to numeric\n",
    "\n",
    "reconvert_to_numeric = ['creation_date','invoice_date']\n",
    "\n",
    "for col in reconvert_to_numeric:\n",
    "    df_combined_encoded[col] = pd.to_numeric(df_combined_encoded[col]) # convert datetime back into numeric\n",
    "\n",
    "df_combined_encoded.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target(y) and features (X)\n",
    "\n",
    "X = df_combined_encoded.drop(['target'], axis=1)\n",
    "y = df_combined_encoded['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use Client_id as index from now on\n",
    "\n",
    "X.set_index('client_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nReturns:\\n        X_resampled : {array-like, dataframe, sparse matrix} of shape                 (n_samples_new, n_features)\\n            The array containing the resampled data.\\n\\n        y_resampled : array-like of shape (n_samples_new,)\\n            The corresponding label of `X_resampled`.'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SMOTE (after split & only for training dataset to prevent data leakage)\n",
    "\n",
    "smote = SMOTE(sampling_strategy='auto') # we initialize smote, 'auto' --> resample all classes but the majority class, we can put a float here to \n",
    "\n",
    "'''When float, it corresponds to the desired ratio of the number of samples in the minority class over the number of samples in the majority class after resampling. Therefore, the ratio is expressed as \n",
    " where \n",
    " is the number of samples in the minority class after resampling and \n",
    " is the number of samples in the majority class.'''\n",
    "\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "'''\n",
    "Returns:\n",
    "        X_resampled : {array-like, dataframe, sparse matrix} of shape \\\n",
    "                (n_samples_new, n_features)\n",
    "            The array containing the resampled data.\n",
    "\n",
    "        y_resampled : array-like of shape (n_samples_new,)\n",
    "            The corresponding label of `X_resampled`.'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'target'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/repos/ml_project_mariusbosch/gas-fraud-team-crime/.venv/lib/python3.11/site-packages/pandas/core/indexes/base.py:3652\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3651\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3652\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3653\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/repos/ml_project_mariusbosch/gas-fraud-team-crime/.venv/lib/python3.11/site-packages/pandas/_libs/index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/repos/ml_project_mariusbosch/gas-fraud-team-crime/.venv/lib/python3.11/site-packages/pandas/_libs/index.pyx:171\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/repos/ml_project_mariusbosch/gas-fraud-team-crime/.venv/lib/python3.11/site-packages/pandas/_libs/index.pyx:214\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine._get_loc_duplicates\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/repos/ml_project_mariusbosch/gas-fraud-team-crime/.venv/lib/python3.11/site-packages/pandas/_libs/index.pyx:222\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine._maybe_get_bool_indexer\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/repos/ml_project_mariusbosch/gas-fraud-team-crime/.venv/lib/python3.11/site-packages/pandas/_libs/index.pyx:114\u001b[0m, in \u001b[0;36mpandas._libs.index._unpack_bool_indexer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'target'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[66], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Correlation before and after resampling\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[39m# correlation of target with features BEFORE resampling\u001b[39;00m\n\u001b[1;32m      5\u001b[0m df_corr_unsampled \u001b[39m=\u001b[39m X_train\n\u001b[0;32m----> 6\u001b[0m df_corr_unsampled\u001b[39m.\u001b[39;49mcorr()[\u001b[39m'\u001b[39;49m\u001b[39mtarget\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39msort_values(ascending\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m      7\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m10\u001b[39m,\u001b[39m10\u001b[39m))\n\u001b[1;32m      8\u001b[0m sns\u001b[39m.\u001b[39mheatmap(df_corr_unsampled\u001b[39m.\u001b[39mcorr()\u001b[39m.\u001b[39mround(\u001b[39m2\u001b[39m), annot\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, cmap\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcoolwarm\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/repos/ml_project_mariusbosch/gas-fraud-team-crime/.venv/lib/python3.11/site-packages/pandas/core/frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3759\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3760\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3761\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3762\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3763\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/repos/ml_project_mariusbosch/gas-fraud-team-crime/.venv/lib/python3.11/site-packages/pandas/core/indexes/base.py:3654\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3653\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3654\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3655\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3656\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3657\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3658\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3659\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'target'"
     ]
    }
   ],
   "source": [
    "# Correlation before and after resampling\n",
    "\n",
    "# correlation of target with features BEFORE resampling\n",
    "\n",
    "df_corr_unsampled = df_combined_encoded\n",
    "df_corr_unsampled.corr()['target'].sort_values(ascending=False)\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.heatmap(df_corr_unsampled.corr().round(2), annot=True, cmap='coolwarm')\n",
    "plt.show()\n",
    "\n",
    "# correlation of target with features after resampling\n",
    "\n",
    "df_corr_sampled = df_combined_encoded\n",
    "df_corr_sampled.corr()['target'].sort_values(ascending=False)\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.heatmap(df_corr_sampled.corr().round(2), annot=True, cmap='coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-reconvert to datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering (dummy variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering (dummy variables)\n",
    "\n",
    "df_invoice= agg_invoice_num_mode_no_monthly_weighting(df_invoice_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge dataframes\n",
    "\n",
    "df_combined = pd.merge(df_client_train, df_invoice, on='client_id', how='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call cleaning function (outlier, date time convert)\n",
    "\n",
    "df_combined = convert_dtype_cat_date(df_combined) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target(y) and features (X)\n",
    "\n",
    "X = df_combined.drop(['target'], axis=1)\n",
    "y = df_combined['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMOTE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
